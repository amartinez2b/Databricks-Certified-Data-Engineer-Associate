{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23cf3d63-7a2e-4f46-9775-a9e110565013",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# NOTA\n",
    "Este script debe ejecutarse en un cluster All-purpose o Job Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f71618-0902-466b-9c09-17b6d265bddb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af51f7f1-e4e9-42bd-a611-7a82486401a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e23a97d-5977-4dd6-af44-3a36eb74e915",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"jdbc_url\",\"jdbc:mysql://www.bigdataybi.com/farmafake?useSSL=false&allowPublicKeyRetrieval=true\")\n",
    "dbutils.widgets.text(\"db_user\",\"\")\n",
    "dbutils.widgets.text(\"db_password\",\"\")\n",
    "jdbc_url = dbutils.widgets.get(\"jdbc_url\")\n",
    "db_user = dbutils.widgets.get(\"db_user\")\n",
    "db_password = dbutils.widgets.get(\"db_password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b806205-3c35-430c-8228-4479a2cd4843",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "import uuid\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, IntegerType, StringType,\n",
    "    DoubleType, TimestampType, ArrayType\n",
    ")\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def generar_clientes(num_registros:int, fake:Faker):\n",
    "    def generar_cedula():\n",
    "        # Dos primeros dígitos: provincia (01–24)\n",
    "        provincia = random.randint(1, 24)\n",
    "        cedula = f\"{provincia:02d}{random.randint(100000000, 999999999)}\"\n",
    "        return cedula[:10]\n",
    "\n",
    "    def generar_ruc():\n",
    "        cedula = generar_cedula()\n",
    "        return cedula + \"001\"\n",
    "\n",
    "    clientes = []\n",
    "    for i in range(1, num_registros + 1):\n",
    "        nombre = fake.name()\n",
    "        genero = random.choice(['masculino', 'femenino'])\n",
    "        \n",
    "        # customer_number: 80% cédula, 20% RUC\n",
    "        if random.random() < 0.8:\n",
    "            customer_number = generar_cedula()\n",
    "        else:\n",
    "            customer_number = generar_ruc()\n",
    "\n",
    "        # Email: 20% inválido o nulo\n",
    "        if random.random() < 0.2:\n",
    "            email = None if random.random() < 0.5 else fake.word()\n",
    "        else:\n",
    "            email = fake.email()\n",
    "\n",
    "        # Teléfono: 30% nulo\n",
    "        if random.random() < 0.3:\n",
    "            telefono = None\n",
    "        else:\n",
    "            telefono = f'09{random.randint(10000000, 99999999)}'\n",
    "\n",
    "        # Fecha de nacimiento: 5% nulo\n",
    "        if random.random() < 0.05:\n",
    "            fecha_nacimiento = None\n",
    "        else:\n",
    "            fecha_nacimiento = fake.date_of_birth(minimum_age=18, maximum_age=80).isoformat()\n",
    "\n",
    "        clientes.append({\n",
    "            'customer_id': i,\n",
    "            'customer_name': nombre,\n",
    "            'email': email,\n",
    "            'telephone': telefono,\n",
    "            'genero': genero,\n",
    "            'date_birthday': fecha_nacimiento,\n",
    "            'customer_number': customer_number\n",
    "        })\n",
    "\n",
    "    df = spark.createDataFrame(clientes)\n",
    "    return df\n",
    "\n",
    "\n",
    "def generar_tienda(fake:Faker):\n",
    "    coordenadas = [\n",
    "        {\"lat\": -0.19083301189289498, \"lon\": -78.4684678293547},\n",
    "        {\"lat\": -0.9743910742811162, \"lon\": -80.6720813210836},\n",
    "        {\"lat\": -1.0036132054724964, \"lon\": -80.62787944051743},\n",
    "    ]\n",
    "    data = []\n",
    "    for i, coord in enumerate(coordenadas, start=1):\n",
    "        data.append({\n",
    "            \"store_id\": i,\n",
    "            \"store_name\": f\"{fake.company()}\",\n",
    "            \"store_lat\": coord[\"lat\"],\n",
    "            \"store_lon\": coord[\"lon\"]\n",
    "        })\n",
    "    df = spark.createDataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def generar_productos(num_registros:int, fake:Faker):\n",
    "    categorias = [\n",
    "        'Analgésicos', 'Antibióticos', 'Antiinflamatorios', 'Antialérgicos',\n",
    "        'Antigripales', 'Antisépticos', 'Vitaminas', 'Antipiréticos'\n",
    "    ]\n",
    "    marcas = ['Pfizer', 'Bayer', 'Novartis', 'Roche', 'Sanofi', 'GSK', 'Merck', 'Abbott']\n",
    "    productos = []\n",
    "    for i in range(1, num_registros + 1):\n",
    "        categoria = random.choice(categorias)\n",
    "        marca = random.choice(marcas)\n",
    "        modelo = fake.bothify(text='MOD-####')\n",
    "        nombre = fake.unique.word().capitalize() + f\" {categoria}\"\n",
    "        costo_unitario = round(random.uniform(2, 100), 2)\n",
    "        descuento = round(random.uniform(0, 0.3), 2)  # hasta 30% de descuento\n",
    "\n",
    "        productos.append({\n",
    "            'product_id': i,\n",
    "            'product_name': nombre,\n",
    "            'category': categoria,\n",
    "            'brand': marca,\n",
    "            'model': modelo,\n",
    "            'cost_unit': costo_unitario,\n",
    "            'discount': descuento\n",
    "        })\n",
    "    df = spark.createDataFrame(productos)\n",
    "    return df\n",
    "\n",
    "\n",
    "def generar_factura(num_registros: int, fake: Faker, customer_df, product_df, store_df):\n",
    "    # Obtener IDs de clientes, tiendas y productos\n",
    "    customer_ids = [row['customer_id'] for row in customer_df.select('customer_id').collect()]\n",
    "    store_ids = [row['store_id'] for row in store_df.select('store_id').collect()]\n",
    "    productos = [(row['product_id'], row['cost_unit']) for row in product_df.select('product_id', 'cost_unit').collect()]\n",
    "    \n",
    "    facturas = []\n",
    "    for _ in range(num_registros):\n",
    "        # Generar UUID único para cada factura\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        \n",
    "        # 90% FA, 10% NC\n",
    "        doc_type = 'FA' if random.random() < 0.9 else 'NC'\n",
    "        secuencial = f\"{random.randint(1, 999999999):09d}\"\n",
    "        doc_code = f\"001-010-{secuencial}\"\n",
    "        customer_id = random.choice(customer_ids)\n",
    "        # 2% de los casos con store_id = NULL\n",
    "        store_id = None if random.random() < 0.02 else random.choice(store_ids)\n",
    "        doc_date = fake.date_time_between(start_date='-2y', end_date='now')\n",
    "        doc_state = random.choice(['A', 'I'])\n",
    "        \n",
    "        # Generar detalles (1 a 5 productos)\n",
    "        num_detalles = random.randint(1, 5)\n",
    "        detalles = []\n",
    "        subtotal = 0.0\n",
    "        descuento_total = 0.0\n",
    "\n",
    "        for _ in range(num_detalles):\n",
    "            product_id, cost_unit = random.choice(productos)\n",
    "            quantity = random.randint(1, 10)\n",
    "            unit_price = round(cost_unit * random.uniform(1.05, 1.15), 2)\n",
    "            discount_pct = round(random.uniform(0, 12), 2)\n",
    "            detalle_total = quantity * unit_price\n",
    "            descuento_total += detalle_total * (discount_pct / 100)\n",
    "            subtotal += detalle_total\n",
    "\n",
    "            detalles.append({\n",
    "                'detail_id': str(uuid.uuid4()),\n",
    "                'product_id': product_id,\n",
    "                'quantity': quantity,\n",
    "                'unit_price': unit_price,\n",
    "                'discount_percent': discount_pct\n",
    "            })\n",
    "\n",
    "        # Totales\n",
    "        doc_subtotal = round(subtotal, 2)\n",
    "        doc_discount = round(descuento_total, 2)\n",
    "        doc_total = round(doc_subtotal - doc_discount, 2)\n",
    "\n",
    "        facturas.append({\n",
    "            'doc_id': doc_id,\n",
    "            'doc_code': doc_code,\n",
    "            'doc_type': doc_type,\n",
    "            'store_id': store_id,\n",
    "            'customer_id': customer_id,\n",
    "            'doc_subtotal': doc_subtotal,\n",
    "            'doc_total': doc_total,\n",
    "            'doc_discount': doc_discount,\n",
    "            'doc_date': doc_date,\n",
    "            'doc_state': doc_state,\n",
    "            'details': detalles\n",
    "        })\n",
    "\n",
    "    # Schema con doc_id como String\n",
    "    details_schema = ArrayType(StructType([\n",
    "        StructField('detail_id', StringType(), True),\n",
    "        StructField('product_id', IntegerType(), True),\n",
    "        StructField('quantity', IntegerType(), True),\n",
    "        StructField('unit_price', DoubleType(), True),\n",
    "        StructField('discount_percent', DoubleType(), True)\n",
    "    ]))\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField('doc_id', StringType(), True),\n",
    "        StructField('doc_code', StringType(), True),\n",
    "        StructField('doc_type', StringType(), True),\n",
    "        StructField('store_id', IntegerType(), True),\n",
    "        StructField('customer_id', IntegerType(), True),\n",
    "        StructField('doc_subtotal', DoubleType(), True),\n",
    "        StructField('doc_total', DoubleType(), True),\n",
    "        StructField('doc_discount', DoubleType(), True),\n",
    "        StructField('doc_date', TimestampType(), True),\n",
    "        StructField('doc_state', StringType(), True),\n",
    "        StructField('details', details_schema, True)\n",
    "    ])\n",
    "\n",
    "    df = spark.createDataFrame(facturas, schema=schema)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_full(jdbc_url:str, db_user:str, db_password:str, fake:Faker, customer_df, store_df, products_df):\n",
    "    invoice_df = generar_factura(10, fake, customer_df, products_df, store_df)\n",
    "    print(f\"[INFO] Writing customers\")\n",
    "    customer_df.write.jdbc(url=jdbc_url, table='customers', mode='overwrite',\n",
    "                           properties={'user': db_user, 'password': db_password})\n",
    "    print(f\"[INFO] Writing stores\")\n",
    "    store_df.write.jdbc(url=jdbc_url, table='stores', mode='overwrite',\n",
    "                        properties={'user': db_user, 'password': db_password})\n",
    "    print(f\"[INFO] Writing products\")\n",
    "    products_df.write.jdbc(url=jdbc_url, table='products', mode='overwrite',\n",
    "                           properties={'user': db_user, 'password': db_password})\n",
    "    print(f\"[INFO] Writing invoices header\")\n",
    "    header_df = invoice_df.select(\n",
    "        'doc_id', 'doc_code', 'doc_type', 'store_id', 'customer_id',\n",
    "        'doc_subtotal', 'doc_total', 'doc_discount', 'doc_date', 'doc_state',\n",
    "        F.from_utc_timestamp(F.current_timestamp(),'America/Guayaquil').alias(\"_writetime\")\n",
    "    )\n",
    "    header_df.write.jdbc(url=jdbc_url, table='invoice_header', mode='overwrite',\n",
    "                         properties={'user': db_user, 'password': db_password})\n",
    "    print(f\"[INFO] Writing invoice details\")\n",
    "    details_df = invoice_df.select('doc_id', F.explode('details').alias('details')).select('doc_id', 'details.*')\\\n",
    "        .withColumn(\"_writetime\",F.from_utc_timestamp(F.current_timestamp(),'America/Guayaquil'))\n",
    "    details_df.write.jdbc(url=jdbc_url, table='invoice_details', mode='overwrite',\n",
    "                          properties={'user': db_user, 'password': db_password})\n",
    "    \n",
    "\n",
    "def load_incremental(jdbc_url: str, db_user: str, db_password: str, fake:Faker, customer_df, product_df, store_df):\n",
    "    fake = Faker('es_ES')\n",
    "    # Generar entre 1 y 5 nuevas facturas\n",
    "    n_nuevas = random.randint(1, 5)\n",
    "    print(f\"[INFO] Generando {n_nuevas} nuevas facturas incrementales...\")\n",
    "    invoice_df = generar_factura(n_nuevas, fake, customer_df, product_df, store_df)\n",
    "    # Cabecera (header)\n",
    "    header_df = invoice_df.select(\n",
    "        F.col('doc_id').cast('string').alias('doc_id'),\n",
    "        'doc_code', 'doc_type', 'store_id', 'customer_id',\n",
    "        'doc_subtotal', 'doc_total', 'doc_discount', 'doc_date', 'doc_state', \n",
    "        F.from_utc_timestamp(F.current_timestamp(),'America/Guayaquil').alias(\"_writetime\")\n",
    "    )\n",
    "    # Detalles (detail)\n",
    "    details_df = invoice_df.select(\n",
    "        F.col('doc_id').cast('string').alias('doc_id'),\n",
    "        F.explode('details').alias('details')\n",
    "    ).select(\n",
    "        'doc_id',\n",
    "        'details.detail_id',\n",
    "        'details.product_id',\n",
    "        'details.quantity',\n",
    "        'details.unit_price',\n",
    "        'details.discount_percent',\n",
    "        F.from_utc_timestamp(F.current_timestamp(),'America/Guayaquil').alias(\"_writetime\")\n",
    "    )\n",
    "    # Escribir (modo append → inserta sin borrar)\n",
    "    print(f\"[INFO] Insertando nuevas filas en invoice_header...\")\n",
    "    header_df.write.jdbc(\n",
    "        url=jdbc_url, table='invoice_header', mode='append',\n",
    "        properties={'user': db_user, 'password': db_password}\n",
    "    )\n",
    "    print(f\"[INFO] Insertando nuevas filas en invoice_details...\")\n",
    "    details_df.write.jdbc(\n",
    "        url=jdbc_url, table='invoice_details', mode='append',\n",
    "        properties={'user': db_user, 'password': db_password}\n",
    "    )\n",
    "    print(f\"[SUCCESS] Se insertaron {n_nuevas} facturas nuevas correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcdf34b1-185e-4b0d-8bcb-25c7a0f13923",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Carga de datos\n",
    "La función load_full hace la primera caga de datos a la base creando tablas y estructuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efec248e-2d12-4a3a-9d76-bcbd8d66fb3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "jdbc_url = dbutils.widgets.get(\"jdbc_url\")\n",
    "db_user = dbutils.widgets.get(\"db_user\")\n",
    "db_password = dbutils.widgets.get(\"db_password\")\n",
    "fake = Faker('es_ES')\n",
    "customer_df = generar_clientes(100, fake)\n",
    "store_df = generar_tienda(fake)\n",
    "products_df = generar_productos(50, fake)\n",
    "load_full(jdbc_url, db_user, db_password, fake, customer_df, store_df, products_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "757fa4b2-4ab8-47ad-945d-b17262add9e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "La función load_incremental inserta nuevos registros cada vez que se ejecuta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a882e99c-385e-4bda-a080-4e7f190d5e97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_incremental(jdbc_url, db_user, db_password, fake, customer_df, products_df, store_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GenFarmaDB",
   "widgets": {
    "db_password": {
     "currentValue": "",
     "nuid": "5598ace3-3eaf-497f-b50f-94d2997d50e0",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "db_password",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "db_password",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "db_user": {
     "currentValue": "",
     "nuid": "57d419b6-e576-44b2-b63b-6444555f1e92",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "db_user",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "db_user",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "jdbc_url": {
     "currentValue": "jdbc:mysql://www.bigdataybi.com/farmafake?useSSL=false&allowPublicKeyRetrieval=true",
     "nuid": "dbcbe496-3593-4a20-96de-83c4d9739119",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "jdbc:mysql://www.bigdataybi.com/farmafake?useSSL=false&allowPublicKeyRetrieval=true",
      "label": null,
      "name": "jdbc_url",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "jdbc:mysql://www.bigdataybi.com/farmafake?useSSL=false&allowPublicKeyRetrieval=true",
      "label": null,
      "name": "jdbc_url",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
