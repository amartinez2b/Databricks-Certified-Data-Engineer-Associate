{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0e9076b-b564-4418-8cf6-60e904d42010",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"volume_path\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac05233d-ebd9-4d0b-b4f1-7c9627fcc03c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "volume_path = dbutils.widgets.get(\"volume_path\")\n",
    "if volume_path == \"\":\n",
    "  raise Exception(\"Please provide a volume path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e00df6ee-fa62-4868-8250-3a32070639f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, ArrayType, DateType\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8bbb921-206e-4044-a30b-8ad70d79fe6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, DateType, IntegerType, DoubleType\n",
    "from faker import Faker\n",
    "import random\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "spark = SparkSession.builder.appName(\"VentasElectrodomesticos\").getOrCreate()\n",
    "\n",
    "# ==================================\n",
    "# ðŸ”¹ Funciones auxiliares\n",
    "# ==================================\n",
    "def generar_correo(nombre):\n",
    "    dominios_buenos = [\"gmail.com\", \"hotmail.com\", \"outlook.com\", \"yahoo.com\"]\n",
    "    dominios_erroneos = [\"gamil.com\", \"hotmial.com\", \"outlok.com\", \"yahho.com\"]\n",
    "    dominio = random.choice(dominios_buenos + dominios_erroneos)\n",
    "    nombre_base = nombre.lower().replace(\" \", \".\")\n",
    "    return f\"{nombre_base}{random.randint(1,999)}@{dominio}\"\n",
    "\n",
    "def generar_telefonos():\n",
    "    n = random.randint(0, 3)\n",
    "    if n == 0:\n",
    "        return []\n",
    "    telefonos = []\n",
    "    for _ in range(n):\n",
    "        if random.random() < 0.2:  # 20% chance de valor nulo\n",
    "            telefonos.append(None)\n",
    "        else:\n",
    "            telefono = \"\".join([str(random.randint(0,9)) for _ in range(10)])\n",
    "            telefonos.append(telefono)\n",
    "    return telefonos\n",
    "\n",
    "# ==================================\n",
    "# ðŸ§â€â™‚ï¸ FunciÃ³n: generar_clientes()\n",
    "# ==================================\n",
    "def generar_clientes(fake, number_of_customers):\n",
    "    clientes_data = []\n",
    "    id = 0\n",
    "    for _ in range(number_of_customers):\n",
    "        id += 1\n",
    "        nombre = fake.name()\n",
    "        genero = random.choice([\"Masculino\", \"Femenino\"])\n",
    "        fecha_nacimiento = fake.date_of_birth(minimum_age=18, maximum_age=80)\n",
    "        correos = [generar_correo(nombre) for _ in range(random.randint(1, 3))][0]\n",
    "        telefonos = generar_telefonos()\n",
    "        \n",
    "        clientes_data.append({\n",
    "            \"id\": id,\n",
    "            \"nombre\": nombre,\n",
    "            \"genero\": genero,\n",
    "            \"fecha_nacimiento\": fecha_nacimiento,\n",
    "            \"correos\": correos,\n",
    "            \"telefonos\": telefonos\n",
    "        })\n",
    "\n",
    "    clientes_schema = StructType([\n",
    "        StructField(\"id\", StringType(), False),\n",
    "        StructField(\"nombre\", StringType(), True),\n",
    "        StructField(\"genero\", StringType(), True),\n",
    "        StructField(\"fecha_nacimiento\", DateType(), True),\n",
    "        StructField(\"correos\", StringType(), True),\n",
    "        StructField(\"telefonos\", ArrayType(StringType()), True)\n",
    "    ])\n",
    "\n",
    "    clientes_df = spark.createDataFrame(clientes_data, schema=clientes_schema)\n",
    "    return clientes_df\n",
    "\n",
    "# ==================================\n",
    "# ðŸ“¦ FunciÃ³n: generar_productos()\n",
    "# ==================================\n",
    "def generar_productos():\n",
    "    productos = [\n",
    "        (\"Televisor\", \"ElectrÃ³nica\"),\n",
    "        (\"Refrigerador\", \"Cocina\"),\n",
    "        (\"Lavadora\", \"Limpieza\"),\n",
    "        (\"Microondas\", \"Cocina\"),\n",
    "        (\"Aspiradora\", \"Limpieza\"),\n",
    "        (\"Horno\", \"Cocina\"),\n",
    "        (\"Licuadora\", \"Cocina\"),\n",
    "        (\"Cafetera\", \"Cocina\"),\n",
    "        (\"Plancha\", \"Limpieza\"),\n",
    "        (\"Ventilador\", \"ClimatizaciÃ³n\"),\n",
    "        (\"Secadora\", \"Limpieza\"),\n",
    "        (\"Tostadora\", \"Cocina\"),\n",
    "        (\"Batidora\", \"Cocina\"),\n",
    "        (\"Parlante Bluetooth\", \"Audio\"),\n",
    "        (\"Purificador de aire\", \"ClimatizaciÃ³n\")\n",
    "    ]\n",
    "\n",
    "    productos_data = []\n",
    "    for i, (producto, categoria) in enumerate(productos, start=1):\n",
    "        productos_data.append({\n",
    "            \"id_product\": i,\n",
    "            \"nombre_producto\": producto,\n",
    "            \"precio_unitario\": round(random.uniform(100, 2000), 2),\n",
    "            \"categoria\": categoria\n",
    "        })\n",
    "    \n",
    "    productos_schema = StructType([\n",
    "        StructField(\"id_product\", IntegerType(), False),\n",
    "        StructField(\"nombre_producto\", StringType(), True),\n",
    "        StructField(\"precio_unitario\", DoubleType(), True),\n",
    "        StructField(\"categoria\", StringType(), True)\n",
    "    ])\n",
    "    productos_df = spark.createDataFrame(productos_data, schema=productos_schema)\n",
    "    return productos_df\n",
    "\n",
    "# ==================================\n",
    "# ðŸ’° FunciÃ³n: generar_ventas()\n",
    "# ==================================\n",
    "def generar_ventas(fake, clientes_df, productos_df, num_ventas):\n",
    "    clientes = [row.id for row in clientes_df.collect()]\n",
    "    productos = productos_df.collect()\n",
    "    \n",
    "    ventas_data = []\n",
    "    for _ in range(num_ventas):\n",
    "        producto = random.choice(productos)\n",
    "        customer_id = random.choice(clientes)\n",
    "        unidades = random.randint(1, 5)\n",
    "        descuento = round(random.uniform(0, 0.25), 2)  # entre 0% y 25%\n",
    "        precio_unitario = producto[\"precio_unitario\"]\n",
    "\n",
    "        ventas_data.append({\n",
    "            \"id_order\": str(uuid.uuid4()),\n",
    "            \"customer_id\": customer_id,\n",
    "            \"id_product\": producto[\"id_product\"],\n",
    "            \"valor_unitario\": precio_unitario,\n",
    "            \"valor_descuento\": descuento,\n",
    "            \"unidades\": unidades,\n",
    "            \"fecha_venta\": fake.date_between(start_date='-1y', end_date='today')\n",
    "        })\n",
    "    \n",
    "    ventas_schema = StructType([\n",
    "        StructField(\"id_order\", StringType(), False),\n",
    "        StructField(\"customer_id\", StringType(), True),\n",
    "        StructField(\"id_product\", IntegerType(), True),\n",
    "        StructField(\"valor_unitario\", DoubleType(), True),\n",
    "        StructField(\"valor_descuento\", DoubleType(), True),\n",
    "        StructField(\"unidades\", IntegerType(), True),\n",
    "        StructField(\"total\", DoubleType(), True),\n",
    "        StructField(\"fecha_venta\", DateType(), True)\n",
    "    ])\n",
    "\n",
    "    ventas_df = spark.createDataFrame(ventas_data, schema=ventas_schema)\n",
    "    return ventas_df\n",
    "\n",
    "# ==================================\n",
    "# ðŸš€ FunciÃ³n principal\n",
    "# ==================================\n",
    "def main():\n",
    "    fake = Faker(\"es_ES\")\n",
    "    # Clientes\n",
    "    df_clientes = generar_clientes(fake, number_of_customers=10)\n",
    "    # Productos\n",
    "    df_productos = generar_productos()\n",
    "    # Ventas\n",
    "    df_ventas = generar_ventas(fake, df_clientes, df_productos, num_ventas=25)\n",
    "    df_clientes.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(f\"{volume_path}/medallion/clientes\")\n",
    "    df_productos.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(f\"{volume_path}/medallion/productos\")\n",
    "    df_ventas.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(f\"{volume_path}/medallion/ventas\")\n",
    "\n",
    "# Ejecutar\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/agustin.martinez@bigdataybi.com/Databricks-Certified-Data-Engineer-Associate/requirements.txt"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GenMedallion",
   "widgets": {
    "volume_path": {
     "currentValue": "/Volumes/demo/dwh/temporal",
     "nuid": "add06824-bd90-4333-8d77-4cfb7887b20b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "volume_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "volume_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
