{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0154b0",
   "metadata": {},
   "source": [
    "%md\n",
    "# Databricks Asset Bundle\n",
    "\n",
    "## Proyecto\n",
    "\n",
    "### Requisitos\n",
    "\n",
    "Tener instalado el cliente de databricks\n",
    "\n",
    "### Crear proyecto\n",
    "\n",
    "Vamos a crear un nuevo proyecto mediante un pequeño formulario\n",
    "\n",
    "```sh\n",
    "cd databricks-project\n",
    "databricks bundle init -p [profile]\n",
    "Search: █\n",
    "? Template to use: \n",
    ">  default-python (The default Python template for Notebooks and Lakeflow)\n",
    "  default-sql\n",
    "  dbt-sql\n",
    "  mlops-stacks\n",
    "↓ experimental-jobs-as-code\n",
    "Unique name for this project [my_project]:\n",
    "Include a stub (sample) notebook in 'my_project/src': \n",
    "  ▸ yes\n",
    "    no\n",
    "Include a stub (sample) Lakeflow Declarative Pipeline in 'my_project/src': \n",
    "  ▸ yes\n",
    "    no\n",
    "Include a stub (sample) Python package in 'my_project/src': \n",
    "  ▸ yes\n",
    "    no\n",
    "Use serverless compute: \n",
    "  ▸ yes\n",
    "    no\n",
    "```\n",
    "\n",
    "Dentro del proyecto vamos a construir un flujo en desarrollo (dev)\n",
    "\n",
    "En el archivo my_project/databricks.yml agrega las variables my_catalog y my_schema\n",
    "\n",
    "```yml\n",
    "# This is a Databricks asset bundle definition for bookstore.\n",
    "# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.\n",
    "# Especifica el nombre del proyecto\n",
    "bundle:\n",
    "  name: bookstore\n",
    "  uuid: 380d75e8-7c19-4055-8252-4914843e8441\n",
    "\n",
    "artifacts:\n",
    "  python_artifact:\n",
    "    type: whl\n",
    "    build: uv build --wheel\n",
    "\n",
    "# Especifica los recursos a incluir en el bundle como jobs y pipelines\n",
    "include:\n",
    "  - resources/*.yml\n",
    "  - resources/*/*.yml\n",
    "\n",
    "# >> NUEVO*** Crea variables para reutilizar en el job\n",
    "variables:\n",
    "  my_catalog:\n",
    "    description: Catalogo por defecto\n",
    "    default: workspace\n",
    "  my_schema:\n",
    "    description: Esquema por defecto\n",
    "    default: bookstore_dev\n",
    "\n",
    "# Especifica los entornos de despliegue\n",
    "targets:\n",
    "  dev:\n",
    "    # The default target uses 'mode: development' to create a development copy.\n",
    "    # - Deployed resources get prefixed with '[dev my_user_name]'\n",
    "    # - Any job schedules and triggers are paused by default.\n",
    "    # See also https://docs.databricks.com/dev-tools/bundles/deployment-modes.html.\n",
    "    mode: development\n",
    "    default: true\n",
    "    workspace:\n",
    "      host: https://dbc-f23c1e0b-86c8.cloud.databricks.com\n",
    "\n",
    "  prod:\n",
    "    mode: production\n",
    "    workspace:\n",
    "      host: https://dbc-f23c1e0b-86c8.cloud.databricks.com\n",
    "      # We explicitly deploy to /Workspace/Users/agustin.martinez@bigdataybi.com to make sure we only have a single copy.\n",
    "      root_path: /Workspace/Users/agustin.martinez@bigdataybi.com/.bundle/${bundle.name}/${bundle.target}\n",
    "    permissions:\n",
    "      - user_name: agustin.martinez@bigdataybi.com\n",
    "        level: CAN_MANAGE\n",
    "```\n",
    "\n",
    "Ahora modifica el notebook my_project/notebook.ipynb agrega este parrafo:\n",
    "\n",
    "```python\n",
    "\n",
    "dbutils.widgets.text(\"catalog\", \"\")\n",
    "dbutils.widgets.text(\"schema\", \"\")\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "print(f\"Catalog: {catalog}, Schema: {schema}\")\n",
    "\n",
    "```\n",
    "\n",
    "Luego envia las variables como parametros en el job my_project/resources/my_project.job.yml\n",
    "\n",
    "```yml\n",
    "# The main job for my_project.\n",
    "resources:\n",
    "  jobs:\n",
    "    my_project_job:\n",
    "      name: my_project_job\n",
    "\n",
    "      trigger:\n",
    "        # Run this job every day, exactly one day from the last run; see https://docs.databricks.com/api/workspace/jobs/create#trigger\n",
    "        periodic:\n",
    "          interval: 1\n",
    "          unit: DAYS\n",
    "\n",
    "      #email_notifications:\n",
    "      #  on_failure:\n",
    "      #    - your_email@example.com\n",
    "\n",
    "      tasks:\n",
    "        - task_key: notebook_task\n",
    "          notebook_task:\n",
    "            notebook_path: ../src/notebook.ipynb\n",
    "            base_parameters:\n",
    "              catalog: ${var.my_catalog}\n",
    "              schema: ${var.my_schema}     \n",
    "\n",
    "        - task_key: refresh_pipeline\n",
    "          depends_on:\n",
    "            - task_key: notebook_task\n",
    "          pipeline_task:\n",
    "            pipeline_id: ${resources.pipelines.my_project_pipeline.id}\n",
    "\n",
    "        - task_key: main_task\n",
    "          depends_on:\n",
    "            - task_key: refresh_pipeline\n",
    "          environment_key: default\n",
    "          python_wheel_task:\n",
    "            package_name: my_project\n",
    "            entry_point: main\n",
    "\n",
    "      # A list of task execution environment specifications that can be referenced by tasks of this job.\n",
    "      environments:\n",
    "        - environment_key: default\n",
    "\n",
    "          # Full documentation of this spec can be found at:\n",
    "          # https://docs.databricks.com/api/workspace/jobs/create#environments-spec\n",
    "          spec:\n",
    "            environment_version: \"2\"\n",
    "            dependencies:\n",
    "              - ../dist/*.whl\n",
    "\n",
    "```\n",
    "\n",
    "### Despliega el bundle\n",
    "\n",
    "```sh\n",
    "cd my_project\n",
    "databricks bundle deploy --target dev\n",
    "databricks bundle deploy --target dev\n",
    "```\n",
    "\n",
    "### Ejecuta el pipeline \n",
    "\n",
    "```sh\n",
    "# Lista los jobs\n",
    "databricks jobs list -p [profile]\n",
    "databricks jobs run-now  [job_id] -p [profile] \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
