{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3502ed06-ac46-41c4-b3e9-a3c1d59cd0c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Conexión de Spark a una base de datos relacional (RDBMS)\n",
    "\n",
    "Para leer datos desde una base de datos relacional (RDBMS) usando Spark, puedes utilizar el conector JDBC. Spark permite conectarse a bases de datos como MySQL, PostgreSQL, SQL Server, entre otras, mediante el uso de la URL JDBC correspondiente y las credenciales de acceso.\n",
    "\n",
    "A continuación se muestra un ejemplo básico de cómo leer una tabla desde una RDBMS usando Spark DataFrame:\n",
    "\n",
    "```python\n",
    "\n",
    "jdbc_url = \"jdbc:mysql://<host>:<puerto>/<base_de_datos>\"\n",
    "table = \"<nombre_de_tabla>\"\n",
    "properties = {\n",
    "    \"user\": \"<usuario>\",\n",
    "    \"password\": \"<contraseña>\"\n",
    "}\n",
    "\n",
    "df = spark.read.jdbc(url=jdbc_url, table=table, properties=properties)\n",
    "display(df)\n",
    "```\n",
    "\n",
    "**Pasos principales:**\n",
    "1. Define la URL JDBC de la base de datos.\n",
    "2. Especifica el nombre de la tabla que deseas leer.\n",
    "3. Proporciona las credenciales y el driver JDBC adecuado.\n",
    "4. Utiliza `spark.read.jdbc()` para cargar los datos en un DataFrame de Spark.\n",
    "5. Usa `display(df)` para visualizar los datos en Databricks.\n",
    "\n",
    "Recuerda que debes tener el driver JDBC correspondiente instalado en tu entorno de Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e4667da-1d8e-48de-84f7-636ba7707295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks Secret Management: Uso de Scopes y dbutils\n",
    "\n",
    "Databricks proporciona un sistema seguro para almacenar y gestionar información sensible, como contraseñas, claves de API y credenciales, mediante el uso de **secretos**. Estos secretos se organizan en **scopes** (ámbitos), que agrupan y controlan el acceso a los secretos.\n",
    "\n",
    "## ¿Qué es un Scope?\n",
    "\n",
    "Un **scope** es una colección de secretos identificada por un nombre. Los scopes permiten gestionar permisos y organizar los secretos según roles, aplicaciones o equipos. Por ejemplo, puedes tener un scope llamado `jdbc` para almacenar credenciales de bases de datos.\n",
    "\n",
    "## ¿Para qué sirven los Secretos en Databricks?\n",
    "\n",
    "Los secretos permiten:\n",
    "- Proteger información sensible evitando exponerla en el código.\n",
    "- Controlar el acceso a credenciales mediante permisos.\n",
    "- Facilitar la rotación y gestión centralizada de claves y contraseñas.\n",
    "\n",
    "## ¿Cómo crear un Scope y un Secreto?\n",
    "\n",
    "1. **Crear un scope** (desde la CLI o API):\n",
    "\n",
    "```bash\n",
    "databricks secrets create-scope mysql-secrets -p [profile]\n",
    "```\n",
    "\n",
    "\n",
    "2. **Crear un secreto dentro del scope**:\n",
    "\n",
    "```bash\n",
    "databricks secrets put-secret --json '{\"scope\":\"mysql-secrets\",\"key\":\"db_password\",\"string_value\":\"TuPasswordSeguro123\"}' -p [profile]\n",
    "```\n",
    "\n",
    "3. **Comandos utiles**\n",
    "\n",
    "```python\n",
    "# Listar todos los scopes disponibles\n",
    "dbutils.secrets.listScopes()\n",
    "\n",
    "# Listar las claves dentro de un scope\n",
    "dbutils.secrets.list(\"mysql-secrets\")\n",
    "\n",
    "# Leer el valor de un secreto\n",
    "db_password = dbutils.secrets.get(\"mysql-secrets\", \"db_password\")\n",
    "```\n",
    "\n",
    "## ¿Cómo recuperar un secreto con dbutils?\n",
    "\n",
    "En un notebook de Databricks, puedes acceder a los secretos usando `dbutils.secrets.get()`:\n",
    "\n",
    "```python\n",
    "# Recuperar el secreto 'password' del scope 'jdbc'\n",
    "password = dbutils.secrets.get(scope=\"jdbc\", key=\"password\")\n",
    "```\n",
    "\n",
    "> **Nota:** Si intentas mostrar el valor del secreto, Databricks lo reemplazará por `[REDACTED]` para evitar filtraciones accidentales.\n",
    "\n",
    "## Resumen\n",
    "\n",
    "- Los secretos en Databricks se agrupan en scopes para una gestión segura y centralizada.\n",
    "- Puedes crear y gestionar secretos usando la CLI, API o SDK.\n",
    "- Recupera los secretos en tus notebooks con `dbutils.secrets.get()` para usarlos de forma segura en tus aplicaciones y flujos de trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3a7568a-0c7b-4c50-b8f2-7ac558317c8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Instalación y uso del cliente de Databricks\n",
    "\n",
    "El cliente de Databricks (Databricks CLI) es una herramienta de línea de comandos que permite interactuar con los recursos de Databricks desde tu terminal o scripts automatizados. Facilita tareas como la gestión de clústeres, trabajos, archivos y otros recursos de Databricks sin necesidad de usar la interfaz web.\n",
    "\n",
    "## ¿Para qué sirve el cliente de Databricks?\n",
    "\n",
    "- Automatizar tareas administrativas y de desarrollo en Databricks.\n",
    "- Gestionar clústeres, trabajos, notebooks, archivos y otros recursos.\n",
    "- Integrar Databricks en flujos de trabajo de CI/CD y scripts personalizados.\n",
    "\n",
    "## Instalación del cliente de Databricks\n",
    "\n",
    "Para instalar el cliente de Databricks, sigue estos pasos:\n",
    "\n",
    "1. **Instala el paquete usando pip:**\n",
    "\n",
    "```bash\n",
    "%pip install databricks-cli\n",
    "```\n",
    "   \n",
    "\n",
    "2. **Verifica la instalación:**\n",
    "\n",
    "```bash\n",
    "databricks --version\n",
    "```\n",
    "   \n",
    "\n",
    "3. **Configura el cliente con tus credenciales:**\n",
    "\n",
    "   Ejecuta el siguiente comando y sigue las instrucciones para ingresar tu host y token de acceso personal:\n",
    "\n",
    "```bash\n",
    "databricks configure --token\n",
    "```\n",
    "   \n",
    "\n",
    "Para más detalles, consulta la [documentación oficial](https://docs.databricks.com/aws/en/dev-tools/cli/install#gsc.tab=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b3cf107-d42f-4b6e-86ed-add412863114",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Lee el secreto"
    }
   },
   "outputs": [],
   "source": [
    "db_password = dbutils.secrets.get(\"mysql-secrets\", \"db_password\")\n",
    "print(db_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79213171-49a5-4ccc-964b-1723e87a68a5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Lee una tabla"
    }
   },
   "outputs": [],
   "source": [
    "db_name = \"fake\"\n",
    "db_user=\"curso\"\n",
    "table_name = \"customers\"\n",
    "db_host = \"www.bigdataybi.com\"\n",
    "db_port = 3306\n",
    "jdbc_url = f\"jdbc:mysql://{db_host}:{db_port}/{db_name}\"\n",
    "df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"dbtable\", table_name) \\\n",
    "    .option(\"user\", db_user) \\\n",
    "    .option(\"password\", db_password) \\\n",
    "    .load()\n",
    "display(df.limit(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5676cd8d-cc1f-4fe0-8604-6e7f19d8c917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Ejercicio práctico:\n",
    "\n",
    "Lee las tablas:\n",
    "- products\n",
    "- sales\n",
    "- shops\n",
    "\n",
    "Todas ellas se encuentran en la base de datos llamada fake dentro del servidor de Mysql"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6894785009459468,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "3.4 - Reading RDBMS",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
