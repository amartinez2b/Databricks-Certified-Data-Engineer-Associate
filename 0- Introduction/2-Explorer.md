# ğŸ“ Tema 2 - Explorando el Workspace, Repositorio Git y CreaciÃ³n de un ClÃºster

---

## 1. Explorando el Workspace de Databricks

El **Workspace** es el entorno de trabajo principal de Databricks. Desde aquÃ­ los usuarios pueden:

- ğŸ“‚ **Workspace:** crear y organizar carpetas, notebooks y librerÃ­as.  
- âš™ï¸ **Compute:** gestionar clÃºsteres y pools de cÃ³mputo.  
- ğŸ“Š **Data:** explorar bases de datos, tablas y Delta Tables.  
- ğŸ“‘ **Repos:** conectar repositorios Git y versionar notebooks.  
- ğŸ“… **Workflows:** programar tareas y pipelines.  
- ğŸ” **SQL Editor:** ejecutar queries SQL y crear dashboards.  

ğŸ‘‰ El Workspace es colaborativo: permite a mÃºltiples usuarios trabajar sobre notebooks compartidos en tiempo real.  

---

## 2. Repositorio Git en Databricks

Databricks permite integrar repositorios Git para **control de versiones** y **colaboraciÃ³n en equipo**.

### Â¿QuÃ© puedes hacer con Repos?
- Clonar un repositorio directamente en el Workspace.  
- Sincronizar notebooks con **GitHub, GitLab, Bitbucket o Azure DevOps**.  
- Usar **branching, pull requests y commits** dentro de Databricks.  

### Pasos para conectar un repo
1. Ir a la secciÃ³n **Repos â†’ Add Repo**.  
2. Pegar la URL de tu repositorio Git.  
3. Autenticarse (token personal de acceso).  
4. Seleccionar la rama con la que trabajarÃ¡s.  
5. Â¡Listo! Ya puedes hacer **git pull / git commit / git push** desde el mismo notebook.  

---

## 3. CreaciÃ³n de un ClÃºster

Un **clÃºster** es un conjunto de recursos de cÃ³mputo donde se ejecutan las tareas de Spark.  
En Databricks, los clÃºsteres pueden ser **interactivos** (para desarrollo) o **job clusters** (para producciÃ³n).

### Pasos para crear un clÃºster
1. Ir a **Compute â†’ Create Cluster**.  
2. Asignar un nombre al clÃºster (ejemplo: `cluster-curso-dea`).  
3. Seleccionar la versiÃ³n de **Databricks Runtime** (ejemplo: 12.x con soporte para ML o Photon).  
4. Definir el **modo de despliegue**:  
   - Single Node (para pruebas pequeÃ±as).  
   - Standard (para procesamiento distribuido).  
5. Seleccionar el tamaÃ±o de las instancias (ejemplo: `i3.xlarge` en AWS o `Standard_DS3_v2` en Azure).  
6. Configurar **Auto Termination** (ejemplo: 30 min de inactividad).  
7. Crear el clÃºster y esperar a que cambie de estado **Pending â†’ Running**.  

### Notas importantes
- âš¡ El clÃºster es donde realmente corre Spark.  
- ğŸ“Š Todos los notebooks deben estar **asociados a un clÃºster** para ejecutarse.  
- ğŸ’° Configurar bien el clÃºster es clave para optimizar costos.  

---

## 4. Ejercicio PrÃ¡ctico ğŸ¯

1. **Explorar Workspace**  
   - Crea una carpeta en tu Workspace llamada `Curso_DataEngineerAssociate`.  
   - Dentro, crea un **notebook vacÃ­o** llamado `Exploracion_Workspace`.

2. **Conectar un Repo Git**  
   - Conecta tu repo (por ejemplo en GitHub o Azure DevOps).  
   - Sincroniza el notebook `Exploracion_Workspace`.  

3. **Crear un ClÃºster**  
   - Crea un clÃºster con nombre `cluster_curso`.  
   - Configura Auto Termination en 30 minutos.  

4. **Validar tu entorno**  
   - Ejecuta el siguiente cÃ³digo en tu notebook:

```python
# Python
print("âœ… Mi Workspace y ClÃºster estÃ¡n listos para trabajar en Databricks!")
``` 